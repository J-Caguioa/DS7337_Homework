{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joseph Caguioa\n",
    "\n",
    "Spring 2020\n",
    "\n",
    "DS 7337: Natural Language Processing\n",
    "\n",
    "Section 404 (Tuesday 2030-2200)\n",
    "\n",
    "HW4 Due: Date of Live Session 8 (2/25/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u><a name=\"toc\">Table of Contents:</a></u>\n",
    "* [Question 1](#question1)\n",
    "* [Question 2](#question2)\n",
    "* [Question 3](#question3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"question1\">Question 1</a> \n",
    "\n",
    "<b>Run one of the part-of-speech (POS) taggers available in Python.\n",
    "  \n",
    "* Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "* Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.</b> <sub>[(back to top)](#toc)</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK, the main natural language processing library used throughout previous homeworks, naturally also has an in-built POS tagger available. It makes sense to try that one first. This tagger uses a Na√Øve Bayes machine learning approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.brown.tagged_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity purposes, the tokenization and tagging functions are combined into a one-liner function that is demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_tag(sentence):\n",
    "    \"\"\"\n",
    "    POS tagging using NLTK.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): The text to be tagged.\n",
    "    \n",
    "    Returns:\n",
    "        tags (list): A list of tokens and POS tags.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>quick</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>brown</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fox</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>jumps</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>over</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>lazy</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>dog</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token NLTK POS Tag\n",
       "0    The           DT\n",
       "1  quick           JJ\n",
       "2  brown           NN\n",
       "3    fox           NN\n",
       "4  jumps          VBZ\n",
       "5   over           IN\n",
       "6    the           DT\n",
       "7   lazy           JJ\n",
       "8    dog           NN\n",
       "9      .            ."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pangram = \"The quick brown fox jumps over the lazy dog.\"\n",
    "pangram_df = pd.DataFrame(token_tag(pangram), columns=[\"Token\", \"NLTK POS Tag\"])\n",
    "pangram_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the NLTK tagger already makes a mistake on this commonly used pangram. The third word, \"brown,\" is labeled a singular noun (NN) when it should be an adjective (JJ).\n",
    "\n",
    "A full list of POS tags in the Penn Treebank Project can be found at the following web link:\n",
    "\n",
    "https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "The NLTK package also provides documentation that can be accessed using `nltk.help.upenn_tagset()`. Tags that are passed to this help function return with acronym expansions and example words, which is helpful for understanding what each tag means. An example, which was used extensively during manual tagging, is demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first task, any long sentence can likely be tagged correctly in full if it is lexically unambiguous, such as by avoiding homographs and homophones. Manually verifying the results of sentences for this unbounded problem could become very time-consuming, especially when interesting candidates include those on the scale of entire one-sentence books. Thus, a relatively interesting sentence longer than ten words, but not ridiculously so, is investigated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>We</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>choose</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>go</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>moon</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>this</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>decade</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>do</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>other</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>things</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>not</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>easy</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>but</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>hard</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>goal</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>serve</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>organize</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>measure</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>best</td>\n",
       "      <td>JJS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>our</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>energies</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>skills</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>challenge</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>one</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>that</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>we</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>willing</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>accept</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>one</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>we</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>unwilling</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>postpone</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>one</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>which</td>\n",
       "      <td>WDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>we</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>intend</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>win</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>others</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>too</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Token NLTK POS Tag\n",
       "0          We          PRP\n",
       "1      choose          VBP\n",
       "2          to           TO\n",
       "3          go           VB\n",
       "4          to           TO\n",
       "5         the           DT\n",
       "6        moon           NN\n",
       "7          in           IN\n",
       "8        this           DT\n",
       "9      decade           NN\n",
       "10        and           CC\n",
       "11         do          VBP\n",
       "12        the           DT\n",
       "13      other           JJ\n",
       "14     things          NNS\n",
       "15          ,            ,\n",
       "16        not           RB\n",
       "17    because           IN\n",
       "18       they          PRP\n",
       "19        are          VBP\n",
       "20       easy           JJ\n",
       "21          ,            ,\n",
       "22        but           CC\n",
       "23    because           IN\n",
       "24       they          PRP\n",
       "25        are          VBP\n",
       "26       hard           JJ\n",
       "27          ,            ,\n",
       "28    because           IN\n",
       "29       that           DT\n",
       "30       goal           NN\n",
       "31       will           MD\n",
       "32      serve           VB\n",
       "33         to           TO\n",
       "34   organize           VB\n",
       "35        and           CC\n",
       "36    measure           VB\n",
       "37        the           DT\n",
       "38       best          JJS\n",
       "39         of           IN\n",
       "40        our         PRP$\n",
       "41   energies          NNS\n",
       "42        and           CC\n",
       "43     skills          NNS\n",
       "44          ,            ,\n",
       "45    because           IN\n",
       "46       that           DT\n",
       "47  challenge           NN\n",
       "48         is          VBZ\n",
       "49        one           CD\n",
       "50       that           IN\n",
       "51         we          PRP\n",
       "52        are          VBP\n",
       "53    willing           JJ\n",
       "54         to           TO\n",
       "55     accept           VB\n",
       "56          ,            ,\n",
       "57        one           CD\n",
       "58         we          PRP\n",
       "59        are          VBP\n",
       "60  unwilling           JJ\n",
       "61         to           TO\n",
       "62   postpone           VB\n",
       "63          ,            ,\n",
       "64        and           CC\n",
       "65        one           CD\n",
       "66      which          WDT\n",
       "67         we          PRP\n",
       "68     intend          VBP\n",
       "69         to           TO\n",
       "70        win           VB\n",
       "71          ,            ,\n",
       "72        and           CC\n",
       "73        the           DT\n",
       "74     others          NNS\n",
       "75          ,            ,\n",
       "76        too           RB\n",
       "77          .            ."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision = \"We choose to go to the moon in this decade and do the other things, \\\n",
    "not because they are easy, but because they are hard, \\\n",
    "because that goal will serve to organize and measure the best of our energies and skills, \\\n",
    "because that challenge is one that we are willing to accept, \\\n",
    "one we are unwilling to postpone, and one which we intend to win, and the others, too.\"\n",
    "\n",
    "pd.set_option('display.max_rows', 80)\n",
    "decision_df = pd.DataFrame(token_tag(decision), columns=[\"Token\", \"NLTK POS Tag\"])\n",
    "decision_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An opening line from John F. Kennedy's 1961 speech, \"The Decision to Go to the Moon,\" is fed into the POS tagger. My manual human check of the output does not detect any major errors. His rhetoric is simple yet evocative, and the words he uses are unambiguous in their meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second task, ambiguous sentences can result in less than 100% correct tagging. One example is the famous buffalo sentence, in which the word \"buffalo\" is repeated eight times: \"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\" It uses three meanings:\n",
    "\n",
    "* Noun: The animal also known as the bison. Note that the word \"buffalo\" counts for both the singular and plural forms.\n",
    "* Verb: An uncommon, informal usage that means \"to puzzle or confuse\" or \"to impress or intimidate.\" (Retrieved from Dictionary.com.) \n",
    "* Proper noun: The city of Buffalo, New York. In this context it could be thought of as a noun adjunct, i.e., it specifies bison that come from the city in New York.\n",
    "\n",
    "As explained on Wikipedia, the meaning can be understood as: \"Buffalo bison, that other Buffalo bison bully, also bully Buffalo bison.\" A simplified parse tree is already available for this sentence on Wikimedia, but some manual tagging is needed to use the Penn treebank tags.\n",
    "\n",
    "| | Buffalo | buffalo | Buffalo | buffalo | buffalo | buffalo | Buffalo | buffalo |\n",
    "| - | - | - | - | - | - | - | - | - |\n",
    "| Parse tags: | PN | N | PN | N | V | V | PN | N |\n",
    "| Penn POS tags: | NNP | NNS | NNP | NNS | VBP | VBP | NNP | NNS |\n",
    "\n",
    "Please note that while I am a native English speaker, I may make mistakes when it comes to manual POS tagging, especially for confusing sentences like this one. For clarity, the POS tag descriptions used in this section follow:\n",
    "\n",
    "* NN: Noun, singular or mass\n",
    "* NNP: Proper noun, singular\n",
    "* NNS: Noun, plural\n",
    "* VBP: Verb, non-3rd person singular present\n",
    "\n",
    "Testing this sentence on the Na√Øve Bayes POS tagger gives the following results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token NLTK POS Tag\n",
       "0  Buffalo          NNP\n",
       "1  buffalo           NN\n",
       "2  Buffalo          NNP\n",
       "3  buffalo           NN\n",
       "4  buffalo           NN\n",
       "5  buffalo           NN\n",
       "6  Buffalo          NNP\n",
       "7  buffalo           NN\n",
       "8        .            ."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffalo_long = \"Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo.\"\n",
    "\n",
    "buffalo_long_df = pd.DataFrame(token_tag(buffalo_long), columns=[\"Token\", \"NLTK POS Tag\"])\n",
    "buffalo_long_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the tagger correctly identified the proper noun version, likely due to capitalization, it failed to identify the verbs. Considering that the verb usage is not commonly used, this is not surprising for a Na√Øve Bayes classifier. It is unlikely that the original Penn Treebank training dataset has many, if any, instances of \"buffalo\" being used as a verb, so it makes sense that the NLTK tagger would have difficulties.\n",
    "\n",
    "Additionally, notice that the other noun instances are called \"NN\" for singular or mass (as in, uncountable) as opposed to \"NNS\" for plural. The tagger likely expects \"buffaloes\" as the plural form (though \"buffalo\" as plural is still considered correct) and receives no help for determining plurality because it does not detect any verbs.\n",
    "\n",
    "Some interesting things happen if the novelty of this sentence is broken by changing \"buffalo\" to \"buffaloes,\" which helps the tagger register plural nouns and usage as a verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Buffalo', 'NNP'),\n",
       " ('buffaloes', 'NNS'),\n",
       " ('Buffalo', 'NNP'),\n",
       " ('buffaloes', 'NNS'),\n",
       " ('buffalo', 'VBD'),\n",
       " ('buffaloes', 'NNS'),\n",
       " ('Buffalo', 'NNP'),\n",
       " ('buffaloes', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_tag(\"Buffalo buffaloes Buffalo buffaloes buffalo buffaloes Buffalo buffaloes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A shorter version that retains ambiguity can trick the tagger in a similar fashion, largely due to the low likelihood of even considering the verb usage of the word \"buffalo.\" Here is the expected output for a simplified, yet still grammatically correct, three-word edition of the sentence.\n",
    "\n",
    "| | Buffalo | buffalo | buffalo |\n",
    "| - | - | - | - |\n",
    "| Parse tags: | N | V | N |\n",
    "| Penn POS tags: | NNS | VBP | NNS |\n",
    "\n",
    "The meaning could be understood as \"Bison bully bison,\" where \"buffalo\" is still being used in the plural. Note that the first capitalization is because that word begins the sentence, not because it means the city as it did before. The actual tag output errs on that and again fails to detect the verb, also likely due to uncommon usage in the training data as suggested before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token NLTK POS Tag\n",
       "0  Buffalo          NNP\n",
       "1  buffalo           NN\n",
       "2  buffalo           NN\n",
       "3        .            ."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffalo_short = \"Buffalo buffalo buffalo.\"\n",
    "\n",
    "buffalo_short_df = pd.DataFrame(token_tag(buffalo_short), columns=[\"Token\", \"NLTK POS Tag\"])\n",
    "buffalo_short_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"question2\">Question 2</a> \n",
    "\n",
    "<b>Run a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "\n",
    "* Does it produce the same or different output?\n",
    "* Explain any differences as best you can.</b> <sub>[(back to top)](#toc)</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy is another NLP library in Python that has POS capabilities. The en_core_web_sm model is a pretrained convolutional neural network (CNN) trained on OntoNotes, which builds on top of the Penn Treebank.\n",
    "\n",
    "An initial run of this section used the simplified Universal Dependencies POS tag set on `token.pos_` before I realized the Penn Treebank tag set was also available via `token.tag_`. The former is briefly demonstrated on the tester sentence just to show that the Universal Dependencies tag set does not go into details like singular versus plural nouns, unlike the Penn tag set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "eng_mod = en_core_web_sm.load()\n",
    "\n",
    "def spacy_tag(sentence):\n",
    "    \"\"\"\n",
    "    POS tagging using spaCy.\n",
    "    \n",
    "    Args:\n",
    "        sentence (str): The text to be tagged.\n",
    "    \n",
    "    Returns:\n",
    "        tags (list): A list of POS tags.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    doc = eng_mod(sentence)\n",
    "    tags = [token.tag_ for token in doc]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK POS Tag</th>\n",
       "      <th>spaCy POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>quick</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>brown</td>\n",
       "      <td>NN</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fox</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>jumps</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>over</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>lazy</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>dog</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token NLTK POS Tag spaCy POS Tag\n",
       "0    The           DT            DT\n",
       "1  quick           JJ            JJ\n",
       "2  brown           NN            JJ\n",
       "3    fox           NN            NN\n",
       "4  jumps          VBZ           NNS\n",
       "5   over           IN            IN\n",
       "6    the           DT            DT\n",
       "7   lazy           JJ            JJ\n",
       "8    dog           NN            NN\n",
       "9      .            .             ."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pangram_spacy = spacy_tag(pangram)\n",
    "pangram_df['spaCy POS Tag'] = pangram_spacy\n",
    "pangram_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly enough, the spaCy tagger makes a different mistake on the pangram than the NLTK tagger. While spaCy correctly calls \"brown\" another adjective, it does not identify \"jumps\" as a verb and instead labels it a plural noun.\n",
    "\n",
    "To address the long and short sentences part of this question, the spaCy tags are printed out alongside the NLTK tags for ease of comparison. First is the long sentence from \"The Decision to Go to the Moon.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK POS Tag</th>\n",
       "      <th>spaCy POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>We</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>choose</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>go</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>moon</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>this</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>decade</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>do</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>other</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>things</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>not</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>easy</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>but</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>hard</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>goal</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>will</td>\n",
       "      <td>MD</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>serve</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>organize</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>measure</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>best</td>\n",
       "      <td>JJS</td>\n",
       "      <td>JJS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>our</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>PRP$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>energies</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>skills</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>because</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>challenge</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>one</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>that</td>\n",
       "      <td>IN</td>\n",
       "      <td>WDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>we</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>willing</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>accept</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>one</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>we</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>are</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>unwilling</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>postpone</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>one</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>which</td>\n",
       "      <td>WDT</td>\n",
       "      <td>WDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>we</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>intend</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>win</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>others</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>too</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Token NLTK POS Tag spaCy POS Tag\n",
       "0          We          PRP           PRP\n",
       "1      choose          VBP           VBP\n",
       "2          to           TO            TO\n",
       "3          go           VB            VB\n",
       "4          to           TO            IN\n",
       "5         the           DT            DT\n",
       "6        moon           NN            NN\n",
       "7          in           IN            IN\n",
       "8        this           DT            DT\n",
       "9      decade           NN            NN\n",
       "10        and           CC            CC\n",
       "11         do          VBP            VB\n",
       "12        the           DT            DT\n",
       "13      other           JJ            JJ\n",
       "14     things          NNS           NNS\n",
       "15          ,            ,             ,\n",
       "16        not           RB            RB\n",
       "17    because           IN            IN\n",
       "18       they          PRP           PRP\n",
       "19        are          VBP           VBP\n",
       "20       easy           JJ            JJ\n",
       "21          ,            ,             ,\n",
       "22        but           CC            CC\n",
       "23    because           IN            IN\n",
       "24       they          PRP           PRP\n",
       "25        are          VBP           VBP\n",
       "26       hard           JJ            JJ\n",
       "27          ,            ,             ,\n",
       "28    because           IN            IN\n",
       "29       that           DT            DT\n",
       "30       goal           NN            NN\n",
       "31       will           MD            MD\n",
       "32      serve           VB            VB\n",
       "33         to           TO            TO\n",
       "34   organize           VB            VB\n",
       "35        and           CC            CC\n",
       "36    measure           VB            VB\n",
       "37        the           DT            DT\n",
       "38       best          JJS           JJS\n",
       "39         of           IN            IN\n",
       "40        our         PRP$          PRP$\n",
       "41   energies          NNS           NNS\n",
       "42        and           CC            CC\n",
       "43     skills          NNS           NNS\n",
       "44          ,            ,             ,\n",
       "45    because           IN            IN\n",
       "46       that           DT            DT\n",
       "47  challenge           NN            NN\n",
       "48         is          VBZ           VBZ\n",
       "49        one           CD            CD\n",
       "50       that           IN           WDT\n",
       "51         we          PRP           PRP\n",
       "52        are          VBP           VBP\n",
       "53    willing           JJ            JJ\n",
       "54         to           TO            TO\n",
       "55     accept           VB            VB\n",
       "56          ,            ,             ,\n",
       "57        one           CD            CD\n",
       "58         we          PRP           PRP\n",
       "59        are          VBP           VBP\n",
       "60  unwilling           JJ            JJ\n",
       "61         to           TO            TO\n",
       "62   postpone           VB            VB\n",
       "63          ,            ,             ,\n",
       "64        and           CC            CC\n",
       "65        one           CD            CD\n",
       "66      which          WDT           WDT\n",
       "67         we          PRP           PRP\n",
       "68     intend          VBP           VBP\n",
       "69         to           TO            TO\n",
       "70        win           VB            VB\n",
       "71          ,            ,             ,\n",
       "72        and           CC            CC\n",
       "73        the           DT            DT\n",
       "74     others          NNS           NNS\n",
       "75          ,            ,             ,\n",
       "76        too           RB            RB\n",
       "77          .            .             ."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_spacy = spacy_tag(decision)\n",
    "decision_df['spaCy POS Tag'] = decision_spacy\n",
    "decision_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 POS tag differences shown in the table. The reasoning behind the taggers' decisions likely stems back to the manual tagging done on the training datasets. The words in question are very commonly used in both parts-of-speech given, which can make diagnosing the correct one tricky.\n",
    "\n",
    "* Index 4 (\"to\", TO, IN): The context is \"We choose to go <u>to</u> the moon...\" where \"to\" is labeled a to by NLTK and preposition or subordinating conjunction by spaCy. Key is the succeeding phrase \"the moon,\" indicating that the \"to\" is helping describe where the infinitive \"to go\" is directed. In this sense it is a preposition. Both IN and TO tags include prepositions in the description, so it seems that both could be valid.\n",
    "* Index 11 (\"do\", VBP, VB): The context is \"We choose...and <u>do</u> the other things...\" where \"do\" is labeled a non-3rd person singular present verb by NLTK and a base form verb by spaCy. Of the two, VBP feels more correct, as the conjunctive \"and\" preceding it suggests that the pronoun \"We\" at the beginning of the sentences is performing both verbs.\n",
    "* Index 50 (\"that\", IN, WDT): The context is \"...because that challenge is one <u>that</u> we are willing to accept...\" where \"that\" is labeled a preposition or subordinating conjunction by NLTK and a wh-determiner by spaCy. Of these, the latter case makes more sense, as \"we are willing to accept\" answers a wh-question, such as \"Which challenge?\"\n",
    "\n",
    "These cases feel like they could go one way or the other, and my personal judgments might pale compared to that of another with more knowledge of linguistics. Nevertheless, no major content or action words (nouns and verbs) that would likely matter more in analysis were labeled incorrectly.\n",
    "\n",
    "Next, the buffalo sentence in both its long and short variants is passed to the spaCy tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('WDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK POS Tag</th>\n",
       "      <th>spaCy POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token NLTK POS Tag spaCy POS Tag\n",
       "0  Buffalo          NNP           NNP\n",
       "1  buffalo           NN           NNP\n",
       "2  Buffalo          NNP           NNP\n",
       "3  buffalo           NN           NNP\n",
       "4  buffalo           NN           NNP\n",
       "5  buffalo           NN           NNP\n",
       "6  Buffalo          NNP           NNP\n",
       "7  buffalo           NN           NNP\n",
       "8        .            .             ."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffalo_long_spacy = spacy_tag(buffalo_long)\n",
    "buffalo_long_df['spaCy POS Tag'] = buffalo_long_spacy\n",
    "buffalo_long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK POS Tag</th>\n",
       "      <th>spaCy POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>buffalo</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token NLTK POS Tag spaCy POS Tag\n",
       "0  Buffalo          NNP           NNP\n",
       "1  buffalo           NN           NNP\n",
       "2  buffalo           NN           NNP\n",
       "3        .            .             ."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffalo_short_spacy = spacy_tag(buffalo_short)\n",
    "buffalo_short_df['spaCy POS Tag'] = buffalo_short_spacy\n",
    "buffalo_short_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spaCy tagger misses the verb usage similarly to the NLTK tagger, but defaults all instances of \"buffalo\" to the singular proper noun. This is interesting, as one would not expect an uncapitalized instance of an animal to be labeled as a proper noun like this. Perhaps, because the verb form is so uncommon, the spaCy tagger perceives these repeated words as compound nouns, which is helped along by the first instance that is simply capitalized because it begins the sentence. It is possible that the OntoNotes training dataset, which has content from more varied sources (including broadcast news, telephone conversations, and web data) than the Penn Treebank dataset (Wall Street Journal stories), resulted in rules that would cause the underlying CNN for the spaCy tagger to behave this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"question3\">Question 3</a> \n",
    "\n",
    "<b>In a news article from this week's news, find a random sentence of at least 10 words.\n",
    "\n",
    "* Looking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "* Now run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    "* Explain any differences between the two taggers and your manual tagging as much as you can.</b> <sub>[(back to top)](#toc)</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major current events this past week include the worldwide spread of COVID-19 and the US Deomcratic presidential primary's ninth debate. But in more entertaining news, a part of the 11-story Affiliated Computer Services building in Dallas, TX survived a planned implosion, resulting in a social media landmark dubbed the \"Leaning Tower of Dallas.\" \n",
    "\n",
    "Read more at \"Leaning Tower of Dallas survived demolition to become city's accidental Instagram star,\" an article written by Charles Trepany for USA Today: https://www.usatoday.com/story/travel/destinations/2020/02/20/leaning-tower-dallas-citys-accidental-tourist-destination/4825127002/\n",
    "\n",
    "While the core will inevitably be fully demolished, it will live on in Internet fame through pictures, including those of a LEGO likeness built by Matt Graham at LEGOLAND Discovery Center Dallas/Fort Worth. The closing line of the article pokes self-aware fun at tourist tendencies and, with 12 words, is the sentence of choice for this task.\n",
    "\n",
    "\"Yes, Graham included little LEGO people ogling it with little LEGO iPhones.\"\n",
    "\n",
    "This sentence is fairly straightforward compared to the buffalo one used in Questions 1 and 2. There are no homonyms introducing ambiguity, and the echoing repetition of \"little LEGO [people/iPhones]\" should be exactly the same in parts of speech, aside from the last word. The proper nouns are the main words that could be expected to trip up the POS taggers, although they would likely default to nouns for unknown words anyway. Below is my manual tagging using the Penn tag set.\n",
    "\n",
    "| | Yes | Graham | included | little | LEGO | people | ogling | it | with | little | LEGO | iPhones |\n",
    "| - | - | - | - | - | - | - | - | - | - | - | - | - | \n",
    "| Penn POS tags: | UH | NNP | VBD | JJ | NNP | NNS | VBG | PRP | IN | JJ | NNP | NNS |\n",
    "\n",
    "And next, here are the results from the NLTK and spaCy taggers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>NLTK POS Tag</th>\n",
       "      <th>spaCy POS Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>UH</td>\n",
       "      <td>UH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Graham</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>included</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>little</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>people</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>ogling</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VBG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>it</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>with</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>little</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>LEGO</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>iPhones</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Token NLTK POS Tag spaCy POS Tag\n",
       "0        Yes           UH            UH\n",
       "1          ,            ,             ,\n",
       "2     Graham          NNP           NNP\n",
       "3   included          VBD           VBD\n",
       "4     little           JJ            JJ\n",
       "5       LEGO          NNP           NNP\n",
       "6     people          NNS           NNS\n",
       "7     ogling          VBG           VBG\n",
       "8         it          PRP           PRP\n",
       "9       with           IN            IN\n",
       "10    little           JJ            JJ\n",
       "11      LEGO          NNP           NNP\n",
       "12   iPhones          NNS           NNS\n",
       "13         .            .             ."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Long live the Leaning Tower of Dallas (ltd)!\n",
    "ltd = \"Yes, Graham included little LEGO people ogling it with little LEGO iPhones.\"\n",
    "\n",
    "ltd_df = pd.DataFrame(token_tag(ltd), columns=[\"Token\", \"NLTK POS Tag\"])\n",
    "ltd_spacy = spacy_tag(ltd)\n",
    "ltd_df['spaCy POS Tag'] = ltd_spacy\n",
    "ltd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, both the NLTK and spaCy POS taggers produced the same results, and they happen to agree with my manual judgments using the Penn tag set.\n",
    "\n",
    "While there are no differences to discuss in this section, from the investigations in Questions 1 and 2, it seems that taggers are more likely to get different results when some of the words used have multiple synsets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
